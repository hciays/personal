{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSu9Jw_xvzhW"
   },
   "source": [
    "## Tutorial 1\n",
    "\n",
    "This tutorial is a combination of coding assignments and written assignments. For the coding assignments, please enter the relevant code in the code cell below. For the written assignments, scan an image and enter it in the cell below the questions. Make a copy of this notebook and submit your solutions. DO NOT DIRECTLY CHANGE THIS NOTEBOOK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smToi8jvzI2Q"
   },
   "source": [
    "**Consider the following corpus:**\n",
    "\n",
    "Natural language processing is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. The goal is a computer capable of understanding the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\n",
    "\n",
    "Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "For the following programming questions, use the NLTK package.\n",
    "\n",
    "**Question 1:** What is the total number of tokens in the corpus? What is the length of the vocabulary (that is, the number of unique tokens) of the corpus? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nDt6bR-VmjsO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens :  107\n",
      "Vocabulary length :  63\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "corpus = \"Natural language processing is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. The goal is a computer capable of understanding the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves. \\n Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.\"\n",
    "token= word_tokenize(corpus)\n",
    "print(\"Total number of tokens : \",len(token))\n",
    "vocabulary = list(set(token))\n",
    "print(\"Vocabulary length : \",len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QR9QWGFG1LHI"
   },
   "source": [
    "**Question 2:** Construct the vocabulary frequency table. Report top 5 rows. Your output should be the list of top 5 frequent words and their corresponding frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Ob9m0TPc2bvK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary table frequency \n",
      "\n",
      "language \t 7\n",
      ", \t 6\n",
      "and \t 6\n",
      "the \t 6\n",
      "of \t 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary table frequency \\n\")\n",
    "most = nltk.FreqDist(token)\n",
    "for var in most.most_common(5):\n",
    "    print(var[0], \"\\t\", var[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7qatDEZ2qNT"
   },
   "source": [
    "**Question 3:** As per Zipf's law, the freqeucy of a word is inversely proportional to its rank. For this small corpus, given the rank and frequency of the top 5 words reported above, calculate the value of the constant for each word.\n",
    "\n",
    "Note: In a sufficeintly large corpus, the constant would be same for all words, which would not be so in our small corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5cifiuM5wqH"
   },
   "source": [
    "**Insert image with answer for question 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRWnmdQk8fI4"
   },
   "source": [
    "**Question 4:** Use the number of tokens and vocabulary size previously computed for this question. With Heaps law in mind, fill up the following missing entries in the table.\n",
    "\n",
    "|**k** |**Î²**|\n",
    "|----|---|\n",
    "|?| 0.5|\n",
    "|6| ?|\n",
    "|?| 0.7|\n",
    "|10| ?|\n",
    "|0.5| ?| \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Mn4swN6-V-O"
   },
   "source": [
    "**Insert image with answer for question 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5USm-Kc-d_P"
   },
   "source": [
    "**Question 5:** What is the lemma and stem of the following words from the corpus? Use NLTK for stemming and lemmatizing. Assume appropriate part of speech based on the corpus for lemmatization. \n",
    "\n",
    "\n",
    "\n",
    "*   processing\n",
    "*   themselves\n",
    "*   accurately\n",
    "*   generation\n",
    "*   linguistics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "JkQiYEtK_TTp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization of  processing  gives  processing \n",
      "\n",
      "Lemmatization of  themselves  gives  themselves \n",
      "\n",
      "Lemmatization of  accurately  gives  accurately \n",
      "\n",
      "Lemmatization of  generation  gives  generation \n",
      "\n",
      "Lemmatization of  linguistics  gives  linguistics \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "word_to_lem =[\"processing\",\"themselves\",\"accurately\",\"generation\",\"linguistics\"]\n",
    "for var in word_to_lem:\n",
    "    print(\"Lemmatization of \", var , \" gives \", lemmatizer.lemmatize(var),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tutorial 2- NLP Course LUH",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
